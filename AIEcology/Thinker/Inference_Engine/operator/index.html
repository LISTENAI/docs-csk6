<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.2">
<title data-react-helmet="true">目前支持量化的op列表如下 | 聆思文档中心</title><meta data-react-helmet="true" property="og:url" content="https://github.com/LISTENAI/docs-csk6/AIEcology/Thinker/Inference_Engine/operator"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="目前支持量化的op列表如下 | 聆思文档中心"><meta data-react-helmet="true" name="description" content="算子目录"><meta data-react-helmet="true" property="og:description" content="算子目录"><link data-react-helmet="true" rel="shortcut icon" href="/docs-csk6/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://github.com/LISTENAI/docs-csk6/AIEcology/Thinker/Inference_Engine/operator"><link data-react-helmet="true" rel="alternate" href="https://github.com/LISTENAI/docs-csk6/AIEcology/Thinker/Inference_Engine/operator" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://github.com/LISTENAI/docs-csk6/AIEcology/Thinker/Inference_Engine/operator" hreflang="x-default"><link rel="stylesheet" href="/docs-csk6/assets/css/styles.b048446a.css">
<link rel="preload" href="/docs-csk6/assets/js/runtime~main.2d336c42.js" as="script">
<link rel="preload" href="/docs-csk6/assets/js/main.70a533e0.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#main" class="skipToContent_vO2r">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" titleclassname="navbar__title" href="/docs-csk6/"><img src="/docs-csk6/img/logo_light.svg" alt="LSOpen Logo" class="themedImage_K3WP themedImage--light_Fy0T navbar__logo"><img src="/docs-csk6/img/logo_dark.svg" alt="LSOpen Logo" class="themedImage_K3WP themedImage--dark_V9oi navbar__logo"></a><a class="navbar__item navbar__link" href="/docs-csk6/chips/4002/Chip_information_4002">芯片</a><a class="navbar__item navbar__link" href="/docs-csk6/tools/LStudio">工具</a><a class="navbar__item navbar__link" href="/docs-csk6/AIsolution/ESR/Quick_start/Scheme_introduction">AI语音应用方案</a><a class="navbar__item navbar__link" href="/docs-csk6/Industrysolution/Scanning_pen/Scheme_introduction">行业Turnkey解决方案</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs-csk6/FAQ/front_page">FAQ</a><a class="navbar__item navbar__link" href="/docs-csk6/school/school">视频课程</a><a class="navbar__item navbar__link" href="/docs-csk6/workorder/workorder">工单</a><div class="react-toggle displayOnlyInLargeViewport_a-w0 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_8pH0"><img src="/docs-csk6/img/light.svg" alt="" class="themedImage_K3WP themedImage--light_Fy0T"><img src="/docs-csk6/img/unlight.svg" alt="" class="themedImage_K3WP themedImage--dark_V9oi"></span></div><div class="react-toggle-track-x"><span class="toggle_8pH0"><img src="/docs-csk6/img/undark.svg" alt="" class="themedImage_K3WP themedImage--light_Fy0T"><img src="/docs-csk6/img/dark.svg" alt="" class="themedImage_K3WP themedImage--dark_V9oi"></span></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="搜索" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" titleclassname="navbar__title" href="/docs-csk6/"><img src="/docs-csk6/img/logo_light.svg" alt="LSOpen Logo" class="themedImage_K3WP themedImage--light_Fy0T navbar__logo"><img src="/docs-csk6/img/logo_dark.svg" alt="LSOpen Logo" class="themedImage_K3WP themedImage--dark_V9oi navbar__logo"></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/chips/4002/Chip_information_4002">芯片</a></li><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/tools/LStudio">工具</a></li><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/AIsolution/ESR/Quick_start/Scheme_introduction">AI语音应用方案</a></li><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/Industrysolution/Scanning_pen/Scheme_introduction">行业Turnkey解决方案</a></li><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/FAQ/front_page">FAQ</a></li><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/school/school">视频课程</a></li><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/workorder/workorder">工单</a></li></ul></div></div></div></nav><nav class="navbar subnavbar--fixed-top sub-navbar" style="padding:0"><div class="navbar__inner subnavbar__inner"><div class="navbar__items" style="overflow-x:auto;padding:var(--ifm-navbar-padding-vertical) var(--ifm-navbar-padding-horizontal)"><a class="subnavbar__item subnavbar__link" dirname="/AIEcology" href="/docs-csk6/AIEcology/Intro/intro">总概</a><a class="subnavbar__item subnavbar__link" dirname="/AIEcology" href="/docs-csk6/AIEcology/Linger/readme">Linger</a><a aria-current="page" class="subnavbar__item subnavbar__link subnavbar__link--active" dirname="/AIEcology" href="/docs-csk6/AIEcology/Thinker/readme">Thinker</a></div></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_Ol8-"><aside class="docSidebarContainer_UfDv"><div class="sidebar_OMtR"><nav class="menu menu--responsive thin-scrollbar menu_2y2e menuWithAnnouncementBar_Lwkw" aria-label="Sidebar navigation"><button aria-label="Open menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg class="sidebarMenuIcon_IcOF" width="24" height="24" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--first menu__link--sublist" type="first" href="#!">项目介绍</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs-csk6/AIEcology/Thinker/Introduction/intro">功能概述</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs-csk6/AIEcology/Thinker/Introduction/env">环境配置</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs-csk6/AIEcology/Thinker/Introduction/how_to_use">使用方法</a></li></ul></li><li class="menu__list-item menu__list-item--current"><a class="menu__link menu__link--first menu__link--sublist menu__link--active" type="first" href="#!">推理引擎</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs-csk6/AIEcology/Thinker/Inference_Engine/compile">编译方法</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs-csk6/AIEcology/Thinker/Inference_Engine/model_quant">模型量化</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs-csk6/AIEcology/Thinker/Inference_Engine/thinker_packer">模型打包</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/docs-csk6/AIEcology/Thinker/Inference_Engine/operator">算子列表</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs-csk6/AIEcology/Thinker/Inference_Engine/Thinke_api">Thinker API</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--first menu__link--sublist" type="first" href="#!">功能示例</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs-csk6/AIEcology/Thinker/Example/example">功能示例</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--first menu__link--sublist" type="first" href="#!">相关工具</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs-csk6/AIEcology/Thinker/Tools/tool">相关工具</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--first menu__link--sublist" type="first" href="#!">贡献内容</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs-csk6/AIEcology/Thinker/Contribution/doc">贡献文档说明</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs-csk6/AIEcology/Thinker/Contribution/code">贡献代码说明</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--first menu__link--sublist" type="first" href="#!">常见问题</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs-csk6/AIEcology/Thinker/FAQ/faq">常见问题</a></li></ul></li><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/AIEcology/Thinker/readme">README</a></li><li class="menu__list-item"><a class="menu__link" href="/docs-csk6/AIEcology/Thinker/README_EN">README_EN</a></li></ul></nav></div></aside><main class="docMainContainer_dRYS"><div class="container padding-top--md padding-bottom--lg center-container"><div class="row"><div class="col docItemCol_+xOG"><div class="docItemContainer_c+5G"><article><div class="markdown"><header><h1 class="h1Heading_5RMM">目前支持量化的op列表如下</h1></header><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="算子目录"></a>算子目录<a class="hash-link" href="#算子目录" title="Direct link to heading">#</a></h2><table><thead><tr><th><strong>Operator</strong></th><th><strong>LUNA</strong></th></tr></thead><tbody><tr><td><a href="#iqadd">iqAdd</a></td><td>Yes</td></tr><tr><td><a href="#iqmul">iqMul</a></td><td>Yes</td></tr><tr><td><a href="#iqcat">iqCat</a></td><td>Yes</td></tr><tr><td><a href="#iqclamp">iqClamp</a></td><td>Yes</td></tr><tr><td><a href="#iqsigmoid">iqSigmoid</a></td><td>Yes</td></tr><tr><td><a href="#relu">Relu</a></td><td>Yes</td></tr><tr><td><a href="#clip">Clip</a></td><td>Yes</td></tr><tr><td><a href="#maxpool">MaxPool2d</a></td><td>Yes</td></tr><tr><td><a href="#avgpool2dint">AvgPool2dInt</a></td><td>Yes</td></tr><tr><td><a href="#conv2dint">Conv2dInt</a></td><td>Yes</td></tr><tr><td><a href="#convtranspose2dint">ConvTranspose2dInt</a></td><td>Yes</td></tr><tr><td><a href="#batchnorm2dint">BatchNorm2dInt</a></td><td>Yes</td></tr><tr><td><a href="#batchnorm1dint">BatchNorm1dInt</a></td><td>Yes</td></tr><tr><td><a href="#linearint">LinearInt</a></td><td>Yes</td></tr><tr><td><a href="#lstmint">LSTMInt</a></td><td>Yes</td></tr><tr><td><a href="#lstmint_is8_is64">LSTMInt_Is8_Is64</a></td><td>Yes</td></tr><tr><td><a href="#lstmint_is8_is64_if32_if32">LSTMInt_Is8_Is64_If32_If32</a></td><td>Yes</td></tr><tr><td><a href="#gruint">GRUInt</a></td><td>Yes</td></tr><tr><td><a href="#gruint_is8_is64">GRUInt_Is8_Is64</a></td><td>Yes</td></tr><tr><td><a href="#gruint_is8_is64_if32">GRUInt_Is8_Is64_If32</a></td><td>Yes</td></tr><tr><td><a href="#Quant">Quant</a></td><td>Yes</td></tr><tr><td><a href="#Dequant">Dequant</a></td><td>Yes</td></tr><tr><td><a href="#bmmint">BmmInt</a></td><td>Yes</td></tr></tbody></table><hr><header><h1 class="h1Heading_5RMM">Operator 命名规则</h1></header><p><code>(MajorName)[_Inputs_Outputs]</code></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="majorname-必需"></a>MajorName 必需<a class="hash-link" href="#majorname-必需" title="Direct link to heading">#</a></h2><p>Operator 主名字,名字内部不允许有符号,仅英文和数字。例如iqMul</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-outputs-可选"></a>Inputs Outputs 可选<a class="hash-link" href="#inputs-outputs-可选" title="Direct link to heading">#</a></h2><p>描述Operator 的输入和输出的信息，输入格式为IXB,输出格式为OXB
其中I表示输入，O表示输出，X表示数据类型，B表示数据宽度。
XB组合为ARM NEON like类型定义</p><table><thead><tr><th>CType</th><th>X</th><th>B</th><th>组合</th></tr></thead><tbody><tr><td>int8_t</td><td>s</td><td>8</td><td>s8</td></tr><tr><td>uint8_t</td><td>u</td><td>8</td><td>u8</td></tr><tr><td>int16_t</td><td>s</td><td>16</td><td>s16</td></tr><tr><td>uint16_t</td><td>u</td><td>16</td><td>u16</td></tr><tr><td>int32_t</td><td>s</td><td>32</td><td>s32</td></tr><tr><td>uint32_t</td><td>u</td><td>32</td><td>u32</td></tr><tr><td>int64_t</td><td>s</td><td>64</td><td>s64</td></tr><tr><td>uint64_t</td><td>u</td><td>64</td><td>u64</td></tr><tr><td>float16</td><td>f</td><td>16</td><td>f16</td></tr><tr><td>float</td><td>f</td><td>32</td><td>f32</td></tr><tr><td>double</td><td>f</td><td>64</td><td>f64</td></tr></tbody></table><hr><header><h1 class="h1Heading_5RMM">术语说明</h1></header><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="量化方式"></a>量化方式<a class="hash-link" href="#量化方式" title="Direct link to heading">#</a></h2><p>在部分op的属性中有platform_quant属性，标识平台相关量化方法，说明如下:</p><ul><li>luna_quant: castor全量化方式(int8-&gt;int8)，针对castor硬件量化，浮点到定点round采用的(x+0.5).floor()计算</li></ul><p>$$(\lfloor x_int<em>\frac{scale_z}{scale_x}+0.5\rfloor+\lfloor y_int</em>\frac{scale_z}{scale_y}+0.5\rfloor).int().clamp(-128,127)$$</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="scale说明"></a>Scale说明<a class="hash-link" href="#scale说明" title="Direct link to heading">#</a></h2><ul><li>scale_i: Input的scale, scale_x,scale_1,scale_2, scale_y同理, bits可以取8，16等</li></ul><p>$$\frac{2^{bits-1}-1}{running_i}$$</p><ul><li>scale_w: Weight的scale, scale_iw, scale_hw同理, bits可以取8，16等</li></ul><p>$$\frac{2^{bits-1}-1}{weight.abs().max()}$$</p><ul><li>scale_o: Output的scale, bits可以取8，16等</li></ul><p>$$\frac{2^{bits-1}-1}{running_o}$$</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="mode参数值"></a>Mode参数值<a class="hash-link" href="#mode参数值" title="Direct link to heading">#</a></h2><ul><li>mode: 所有模式下的device信息</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="onnx类型值"></a>onnx类型值<a class="hash-link" href="#onnx类型值" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="类型说明"></a>类型说明<a class="hash-link" href="#类型说明" title="Direct link to heading">#</a></h3><table><thead><tr><th>Group</th><th>Types</th><th>Description</th></tr></thead><tbody><tr><td>Floating Point Types</td><td>FLOAT16, FLOAT32, FLOAT64</td><td>Values adhering to the IEEE 754-2008 standard representation of floating-point data.</td></tr><tr><td>Signed Integer Types</td><td>INT8, INT16, INT32, INT64</td><td>Signed integers are supported for 8-64 bit widths.</td></tr><tr><td>Unsigned Integer Types</td><td>UINT8, UINT16</td><td>Unsigned integers of 8 or 16 bits are supported.</td></tr><tr><td>Complex Types</td><td>COMPLEX64, COMPLEX128</td><td>A complex number with either 32- or 64-bit real and imaginary parts.</td></tr><tr><td>Other</td><td>STRING</td><td>Strings represent textual data. All strings are encoded using UTF-8.</td></tr><tr><td>Other</td><td>BOOL</td><td>Boolean values represent data with only two values, typically true and false.</td></tr></tbody></table><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="类型和值"></a>类型和值<a class="hash-link" href="#类型和值" title="Direct link to heading">#</a></h3><table><thead><tr><th>类型</th><th>值</th></tr></thead><tbody><tr><td>UNDEFINED</td><td>0</td></tr><tr><td>FLOAT32</td><td>1</td></tr><tr><td>UINT8</td><td>2</td></tr><tr><td>INT8</td><td>3</td></tr><tr><td>UINT16</td><td>4</td></tr><tr><td>INT16</td><td>5</td></tr><tr><td>INT32</td><td>6</td></tr><tr><td>INT64</td><td>7</td></tr><tr><td>STR</td><td>8</td></tr><tr><td>BOOL</td><td>9</td></tr><tr><td>FLOAT16</td><td>10</td></tr><tr><td>UINT32</td><td>12</td></tr><tr><td>UINT64</td><td>13</td></tr><tr><td>COMPLEX64</td><td>14</td></tr><tr><td>COMPLEX128</td><td>15</td></tr><tr><td>BFLOAT16</td><td>16</td></tr></tbody></table><hr><header><h1 class="h1Heading_5RMM">iqAdd</h1></header><p>量化数据加法,由linger导出</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs"></a>Inputs<a class="hash-link" href="#inputs" title="Direct link to heading">#</a></h3><ul><li>x:T,第1个操作tensor</li><li>y:T,第2个操作tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs"></a>Outputs<a class="hash-link" href="#outputs" title="Direct link to heading">#</a></h3><ul><li>o:T,结果</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr"></a>Attr<a class="hash-link" href="#attr" title="Direct link to heading">#</a></h3><ul><li>scale_x:float,required,x的scale</li><li>scale_y:float,required,y的scale</li><li>scale_o:float,required,输出值o的scale</li><li>platform_quant:string,required,支持包括luna_quant，默认为luna_quant</li><li>mode: string, required</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints"></a>Type Constraints<a class="hash-link" href="#type-constraints" title="Direct link to heading">#</a></h3><p>-T:int8,int16,int32</p><hr><header><h1 class="h1Heading_5RMM">iqMul</h1></header><ul><li>量化数据乘法</li><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-1"></a>Inputs<a class="hash-link" href="#inputs-1" title="Direct link to heading">#</a></h3><ul><li>x:T,第1个操作tensor</li><li>y:T,第2个操作tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-1"></a>Outputs<a class="hash-link" href="#outputs-1" title="Direct link to heading">#</a></h3><ul><li>o:T,乘法结果</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-1"></a>Attr<a class="hash-link" href="#attr-1" title="Direct link to heading">#</a></h3><ul><li>scale_x:float,required,x的scale</li><li>scale_y:float,required,y的scale</li><li>scale_o:float,required,输出值o的scale</li><li>platform_quant:string,required,支持包括luna_quant，默认为luna_quant</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-1"></a>Type Constraints<a class="hash-link" href="#type-constraints-1" title="Direct link to heading">#</a></h3><p>-T:tensor(int8),tensor(int16),tensor(int32)</p><hr><header><h1 class="h1Heading_5RMM">iqCat</h1></header><ul><li>tensor cat 操作</li><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs1---"></a>Inputs（1 - ∞）<a class="hash-link" href="#inputs1---" title="Direct link to heading">#</a></h3><ul><li>x0:T,第0个tensor</li><li>x1:T,第1个tensor</li><li>x2:T,第2个tensor</li><li>...</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-2"></a>Outputs<a class="hash-link" href="#outputs-2" title="Direct link to heading">#</a></h3><ul><li>o:T,concat输出tensor</li><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-2"></a>Attr<a class="hash-link" href="#attr-2" title="Direct link to heading">#</a></h3><p><code>个数与inputs相同</code></p><ul><li>scale_x_0:float,required,第0个tensor的scale</li><li>scale_x_1:float,required,第1个tensor的scale</li><li>scale_x_2:float,required,第2个tensor的scale</li><li>...</li><li>dim:int,required,concat的轴，取值[-r, r-1],其中 r = rank(inputs)</li><li>scale_o:float,required,concat后o的tensor</li><li>platform_quant:string,required,平台量化配置，支持包括luna_quant，默认为luna_quant</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-2"></a>Type Constraints<a class="hash-link" href="#type-constraints-2" title="Direct link to heading">#</a></h3><ul><li>T:int8</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="onnxinfer-implementation"></a>OnnxInfer Implementation<a class="hash-link" href="#onnxinfer-implementation" title="Direct link to heading">#</a></h3><ul><li>会被自动解析为对输入分别做requant操作，再调用原始的concat算子实现，采用普通的scale转换方式进行requant操作之后concat</li></ul><hr><header><h1 class="h1Heading_5RMM">iqClamp</h1></header><ul><li>数据截断</li><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-2"></a>Inputs<a class="hash-link" href="#inputs-2" title="Direct link to heading">#</a></h3><ul><li>x:T,需要截断的tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-3"></a>Outputs<a class="hash-link" href="#outputs-3" title="Direct link to heading">#</a></h3><ul><li>y:T,截断后的结果 </li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-3"></a>Attr<a class="hash-link" href="#attr-3" title="Direct link to heading">#</a></h3><ul><li>scale_x:float,required,输入x的scale</li><li>scale_o:float,required,输出y的scale</li><li>platform_quant:string,required,平台属性</li><li>min:float,required,clamp最小值</li><li>max:float,required,clamp最大值</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-3"></a>Type Constraints<a class="hash-link" href="#type-constraints-3" title="Direct link to heading">#</a></h3><p>-T:tensor(int8)</p><hr><header><h1 class="h1Heading_5RMM">iqSigmoid</h1></header><ul><li>数据sigmoid激活</li><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-3"></a>Inputs<a class="hash-link" href="#inputs-3" title="Direct link to heading">#</a></h3><ul><li>x:T1,输入tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-4"></a>Outputs<a class="hash-link" href="#outputs-4" title="Direct link to heading">#</a></h3><ul><li>y:T2,sigmoid后的结果</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-4"></a>Attr<a class="hash-link" href="#attr-4" title="Direct link to heading">#</a></h3><ul><li>scale_x:float,required,输入x的scale</li><li>scale_o:float,required,输出y的scale</li><li>platform_quant:string,required,平台属性</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-4"></a>Type Constraints<a class="hash-link" href="#type-constraints-4" title="Direct link to heading">#</a></h3><ul><li>T1:tensor(int8)</li><li>T2:tensor(uint8)</li></ul><hr><header><h1 class="h1Heading_5RMM">Relu</h1></header><ul><li>y = max(0, x)</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-4"></a>Inputs<a class="hash-link" href="#inputs-4" title="Direct link to heading">#</a></h3><ul><li>x:T,输入tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-5"></a>Outputs<a class="hash-link" href="#outputs-5" title="Direct link to heading">#</a></h3><ul><li>y:T,relu后的结果</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-5"></a>Type Constraints<a class="hash-link" href="#type-constraints-5" title="Direct link to heading">#</a></h3><ul><li>T:tensor(int8),tensor(int32),tensor(float)</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="onnxinfer-implementation-1"></a>OnnxInfer Implementation<a class="hash-link" href="#onnxinfer-implementation-1" title="Direct link to heading">#</a></h3><p>= 此处的relu算子为自定义op, domain=onnxinfer, 支持int8的输入输出, 同时也支持原始relu算子的多种数据类型的输入</p><hr><header><h1 class="h1Heading_5RMM">Clip</h1></header><ul><li>Clip算子为Relu6的导出模式，为标准的onnx节点，支持int8的输入输出</li><li>与clamp区别:clip有3个输入，1个输出，即min_thresh和max_thresh作为输入，clamp的min和max是属性</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-5"></a>Inputs<a class="hash-link" href="#inputs-5" title="Direct link to heading">#</a></h3><ul><li>x:T,输入数据tensor</li><li>min_thresh:T,截断的最小值</li><li>max_thresh:T,截断的最大值</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-6"></a>Outputs<a class="hash-link" href="#outputs-6" title="Direct link to heading">#</a></h3><ul><li>y:T,截断后的输出tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-6"></a>Type Constraints<a class="hash-link" href="#type-constraints-6" title="Direct link to heading">#</a></h3><ul><li>T:tensor(int8), tensor(float)</li></ul><hr><header><h1 class="h1Heading_5RMM">AvgPool2dInt</h1></header><ul><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-6"></a>Inputs<a class="hash-link" href="#inputs-6" title="Direct link to heading">#</a></h3><ul><li>x:T,格式(N x C x H x W),输入tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-7"></a>Outputs<a class="hash-link" href="#outputs-7" title="Direct link to heading">#</a></h3><ul><li>y:T,格式(N x C x H x W),输出tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-5"></a>Attr<a class="hash-link" href="#attr-5" title="Direct link to heading">#</a></h3><ul><li>kernel_shape:int2,required,pool2d 的kernel大小</li><li>strides:int2,required,pool2d 的stride</li><li>pads:int2,required,pool2d的pad大小</li><li>ceil_mode:bool,是否为ceil模式</li><li>data_bits:int,required,输入数据bit数，当前仅仅支持8</li><li>scale_x:float,required,输入tensor的scale</li><li>scale_o:float,required,输出tensor的scale</li><li>o_bits:输出bit数,如果没有该属性,意味着float</li><li>platform_quant:string,required,支持luna_quant</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-7"></a>Type Constraints<a class="hash-link" href="#type-constraints-7" title="Direct link to heading">#</a></h3><ul><li>T: tensor(int8)</li></ul><hr><header><h1 class="h1Heading_5RMM">Conv2dInt</h1></header><ul><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-7"></a>Inputs<a class="hash-link" href="#inputs-7" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(N X C X H X W),卷积的激活值</li><li>weight:T1,格式(M x C/group x kH x kW),M是feature maps数量,C是channels数量,kH和kW是feature map的高和长</li><li>bias:T2,optional,1D bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-8"></a>Outputs<a class="hash-link" href="#outputs-8" title="Direct link to heading">#</a></h3><ul><li>o:T3,格式(N X C X H X W),卷积后的输出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-6"></a>Attr<a class="hash-link" href="#attr-6" title="Direct link to heading">#</a></h3><ul><li>dilations:int or int2,required</li><li>group:int,required,输入到输出的卷积块数</li><li>kernel_shape:int or int2,required,卷积核大小</li><li>pads:int or int2,required,两边pad 0的大小</li><li>strides:int or int2,required,卷积的stride</li><li>scale_x:float,required,输入x的feature maps的scale</li><li>scale_w:float,required,weight的scale</li><li>scale_o:float,optional,输出o的scale,没有该属性意味着浮点输出</li><li>data_bits:int,required,x的量化bit数,比如8 表示8bit量化的</li><li>parameter_bits:int,required,weight的量化bit数,比如8 表示8bit量化的</li><li>o_bits:int,optional,输出的o的量化bit数,比如8 表示8bit量化的,没有该属性意味着浮点输出</li><li>platform_quant:string,平台属性,luna_quant, mlu_quant,gpu_quant,
<code>如果torchintx处设置platform_quant为mlu_quant/gpu_quant,则out_bits=None,onnx中则不会有o_bits属性</code></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-8"></a>Type Constraints<a class="hash-link" href="#type-constraints-8" title="Direct link to heading">#</a></h3><ul><li>T1:tensor(int8)</li><li>T2:tensor(int16),tensor(int32),tensor(float)</li><li>T3:tensor(int8),tensor(float)</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="onnxinfer-implementation-2"></a>OnnxInfer Implementation<a class="hash-link" href="#onnxinfer-implementation-2" title="Direct link to heading">#</a></h3><ul><li>在onnxinfer中运行时，会被解析成ConvInteger + Add(bias) + Requant 的操作来实现</li></ul><hr><header><h1 class="h1Heading_5RMM">ConvTranspose2dInt</h1></header><ul><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-8"></a>Inputs<a class="hash-link" href="#inputs-8" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(N x C x H x W),输入反卷积数据</li><li>weight:T1,格式(C x M/group x kH x kW),反卷积的weight,M是feature map数,C是通道数，kH和kW是feaaturemap的高和长</li><li>bias:T2,optional,1D bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-9"></a>Outputs<a class="hash-link" href="#outputs-9" title="Direct link to heading">#</a></h3><ul><li>o:T3,格式(N x C x H x W),反卷积结果</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-7"></a>Attr<a class="hash-link" href="#attr-7" title="Direct link to heading">#</a></h3><ul><li>dilations:int or int2,required</li><li>group:int,required,输入到输出的反卷积块数</li><li>kernel_shape:int or int2,required,反卷积核大小</li><li>pads:int or int2,required,两边pad 0的大小,<code>dilation * (kernel_size - 1) - padding</code></li><li>strides:int or int2,required,反卷积的stride</li><li>output_padding:int or int2,required,反卷积输出的额外pad大小  </li><li>scale_x:float,required,输入x的feature maps的scale</li><li>scale_w:float,required,weight的scale</li><li>scale_o:float,optional,输出o的scale,没有该属性意味着浮点输出</li><li>data_bits:int,required,x的量化bit数,比如8 表示8bit量化的</li><li>parameter_bits:int,required,weight的量化bit数,比如8 表示8bit量化的</li><li>o_bits:int,optional,输出的o的量化bit数,比如8 表示8bit量化的,没有该属性意味着浮点输出</li><li>platform_quant:string,平台属性,luna_quant, mlu_quant,gpu_quant,
<code>如果torchintx处设置platform_quant为mlu_quant/gpu_quant,则out_bits=None,onnx中则不会有o_bits属性</code></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-9"></a>Type Constraints<a class="hash-link" href="#type-constraints-9" title="Direct link to heading">#</a></h3><ul><li>T1:tensor(int8)</li><li>T2:tensor(int16),tensor(int32),tensor(float)</li><li>T3:tensor(int8),tensor(float)</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="onnxinfer-implementation-3"></a>OnnxInfer Implementation<a class="hash-link" href="#onnxinfer-implementation-3" title="Direct link to heading">#</a></h3><ul><li>在onnxinfer中运行时，会被解析为自定义算子ConvTranspose2dInteger + Requant 的操作</li></ul><hr><header><h1 class="h1Heading_5RMM">BatchNorm2dInt</h1></header><ul><li>linger导出</li><li>算法:<code>o = x * mul_w + add_b</code></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-9"></a>Inputs<a class="hash-link" href="#inputs-9" title="Direct link to heading">#</a></h3><ul><li>x:T,格式(N x C X H x W),batchnorm的输入feature maps</li><li>mul_w:T,batch_norm 化简后的乘法系数</li><li>add_b:T,batch_norm 化简后的加法系数</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-10"></a>Outputs<a class="hash-link" href="#outputs-10" title="Direct link to heading">#</a></h3><ul><li>o:T,格式(N x C X H x W),输出tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-8"></a>Attr<a class="hash-link" href="#attr-8" title="Direct link to heading">#</a></h3><ul><li>scale_mul_x:float,required,乘法操作的x的scale</li><li>scale_mul_w:float,required,乘法操作的w的scale</li><li>scale_mul_o:float,required,乘法输出的scale</li><li>scale_add_b:float,required,加法的weight b的scale</li><li>scale_add_o:float,required,输出o的scale</li><li>data_bits:int,required,输入数据bit数</li><li>parameter_bits:int,required,默认为8</li><li>o_bits:int,required,输出bit数,也代表着中间乘法操作后(加法前)的中间运算bit数</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-10"></a>Type Constraints<a class="hash-link" href="#type-constraints-10" title="Direct link to heading">#</a></h3><ul><li>T:tensor(int8),tensor(int16),tensor(int32),</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="onnxinfer-implementation-4"></a>OnnxInfer Implementation<a class="hash-link" href="#onnxinfer-implementation-4" title="Direct link to heading">#</a></h3><ul><li>此处BatchNorm2dInt实现为乘加操作</li></ul><hr><header><h1 class="h1Heading_5RMM">LinearInt</h1></header><ul><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-10"></a>Inputs<a class="hash-link" href="#inputs-10" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(B x M x K),输入全连接数据</li><li>weight:T1,格式(K x N),全连接的weight</li><li>bias:T2,optional,1D bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-11"></a>Outputs<a class="hash-link" href="#outputs-11" title="Direct link to heading">#</a></h3><ul><li>o:T3,格式(B x N),全连接</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-9"></a>Attr<a class="hash-link" href="#attr-9" title="Direct link to heading">#</a></h3><ul><li>scale_x:float,required,输入x的feature maps的scale</li><li>scale_w:float,required,weight的scale</li><li>scale_o:float,optional,输出o的scale,没有该属性意味着浮点输出</li><li>data_bits:int,required,x的量化bit数,比如8 表示8bit量化的</li><li>parameter_bits:int,required,weight的量化bit数,比如8 表示8bit量化的</li><li>o_bits:int,optional,输出的o的量化bit数,比如8 表示8bit量化的,没有该属性意味着浮点输出</li><li>platform_quant:string,luna_quant, mlu_quant,gpu_quant,
<code>如果torchintx处设置platform_quant为mlu_quant/gpu_quant,则out_bits=None,onnx中则不会有o_bits属性</code></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-11"></a>Type Constraints<a class="hash-link" href="#type-constraints-11" title="Direct link to heading">#</a></h3><ul><li>T1:tensor(int8)</li><li>T2:tensor(int16),tensor(int32),tensor(float)</li><li>T3:tensor(int8),tensor(float)</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="onnxinfer-implementation-5"></a>OnnxInfer Implementation<a class="hash-link" href="#onnxinfer-implementation-5" title="Direct link to heading">#</a></h3><ul><li>在onnxinfer中运行时，会被解析成 MatMulInteger + Add(bias) + Requant 的操作来实现</li></ul><hr><header><h1 class="h1Heading_5RMM">LSTMInt</h1></header><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-11"></a>Inputs<a class="hash-link" href="#inputs-11" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(B x T x D)或者(T x B x D),输入数据,B 是batch，T是time，D是input dim</li><li>weight_ih:T1,输入连接的weight</li><li>weight_hh:T1,hidden连接的weight</li><li>bias_ih:T2,输入连接的weight后的bias</li><li>bias_hh:T2,hidden连接的weight后的bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-12"></a>Outputs<a class="hash-link" href="#outputs-12" title="Direct link to heading">#</a></h3><ul><li>output:有o_bits属性为T3，没有为T4</li><li>hidden_state:T4</li><li>cell_state:T4</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-10"></a>Attr<a class="hash-link" href="#attr-10" title="Direct link to heading">#</a></h3><ul><li>scale_i:float,required,输入数据scale</li><li>scale_h:float,required,hidden scale</li><li>scale_iw:float,required,weight_ih的scale</li><li>scale_hw:float,required,weight_hh的scale</li><li>scale_io:float,optional,输入矩阵计算(Wi*Xi+Bi)的输出量化scale</li><li>scale_ho:float,optional,隐层矩阵计算(Wh*H+Bh)的输出量化scale</li><li>scale_o:float,optional,如果o_bits没有,scale_o为空</li><li>o_bits:int,optional,觉得输出是否做量化</li><li>platform_quant:string,required,对应不同的硬件平台</li><li>data_bits:int,required，输入量化bit数</li><li>parameter_bits:int,required,weight_iw,weight_hw的数据位数</li><li>batch_first:int,required,1表明输入数据是否是B<em>T</em>D模式，0表明是T<em>B</em>D输入格式</li><li>dropout:float,required,对应标准lstm中的dropout操作，量化是全部为0，不做dropout操作</li><li>go_gorward:int,required,针对双向lstm的量化导出，1表示正向，0表示反向</li><li>num_layers:int,required,量化只支持num_layers=1</li><li>input_size:int,required,输入数据维度</li><li>hidden_size:int,required,隐层状态维度</li><li>table_len:int,optional,如果使用查表法,有此属性,表示表长度</li><li>sigmoid_bound:float,optional,sigmoid查表计算的查表边界</li><li>tanh_bound:float,optional,tanh查表计算的查表边界</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-12"></a>Type Constraints<a class="hash-link" href="#type-constraints-12" title="Direct link to heading">#</a></h3><ul><li><p>T1:tensor(int8)</p></li><li><p>T2:tensor(int32)</p></li><li><p>T3:tensor(int8)</p></li><li><p>T4:tensor(float32)</p><p><img src="/docs-csk6/assets/images/lstm_int-008981d38bfb11aff8c7629dd9dfa4cc.png"></p></li></ul><hr><header><h1 class="h1Heading_5RMM">LSTMInt_Is8_Is64</h1></header><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-12"></a>Inputs<a class="hash-link" href="#inputs-12" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(B x T x D)或者(T x B x D),输入数据,B 是batch，T是time，D是input dim</li><li>batch_seq:T5,输入x的长度tensor，表示成list为[T0,T1,...],T0表示输入x的第0个tensor的T的实际长度,list长度为B</li><li>weight_ih:T1,输入连接的weight</li><li>weight_hh:T1,hidden连接的weight</li><li>bias_ih:T2,输入连接的weight后的bias</li><li>bias_hh:T2,hidden连接的weight后的bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-13"></a>Outputs<a class="hash-link" href="#outputs-13" title="Direct link to heading">#</a></h3><ul><li>output:有o_bits属性为T3，没有为T4</li><li>hidden_state:T4</li><li>cell_state:T4</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-11"></a>Attr<a class="hash-link" href="#attr-11" title="Direct link to heading">#</a></h3><ul><li>和LSTMInt一致</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-13"></a>Type Constraints<a class="hash-link" href="#type-constraints-13" title="Direct link to heading">#</a></h3><ul><li><p>T1:tensor(int8)</p></li><li><p>T2:tensor(int32)</p></li><li><p>T3:tensor(int8)</p></li><li><p>T4:tensor(float32)</p></li><li><p>T5:tensor(int64)</p><p><img src="/docs-csk6/assets/images/lstm_int_with_batch_length-7819f16f2f587e33720ace27a0eeef59.png"></p></li></ul><hr><header><h1 class="h1Heading_5RMM">LSTMInt_Is8_Is64_If32_If32</h1></header><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-13"></a>Inputs<a class="hash-link" href="#inputs-13" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(B x T x D)或者(T x B x D),输入数据,B 是batch，T是time，D是input dim</li><li>batch_seq:T5,输入x的长度tensor，表示成list为[T0,T1,...],T0表示输入x的第0个tensor的T的实际长度,list长度为B</li><li>hidden_state:T4,隐层单元输入</li><li>cell_state:T4,记忆单元输入</li><li>weight_ih:T1,输入连接的weight</li><li>weight_hh:T1,hidden连接的weight</li><li>bias_ih:T2,输入连接的weight后的bias</li><li>bias_hh:T2,hidden连接的weight后的bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-14"></a>Outputs<a class="hash-link" href="#outputs-14" title="Direct link to heading">#</a></h3><ul><li>output:有o_bits属性为T3，没有为T4</li><li>hidden_state:T4</li><li>cell_state:T4</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-12"></a>Attr<a class="hash-link" href="#attr-12" title="Direct link to heading">#</a></h3><ul><li>和LSTMInt一致</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-14"></a>Type Constraints<a class="hash-link" href="#type-constraints-14" title="Direct link to heading">#</a></h3><ul><li><p>T1:tensor(int8)</p></li><li><p>T2:tensor(int32)</p></li><li><p>T3:tensor(int8)</p></li><li><p>T4:tensor(float32)</p></li><li><p>T5:tensor(int64)</p><p><img src="/docs-csk6/assets/images/lstm_int_with_batch_length_and_state-f3e68bfdcacc9855df374b7de47c6e22.png"></p></li></ul><hr><header><h1 class="h1Heading_5RMM">GRUInt</h1></header><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-14"></a>Inputs<a class="hash-link" href="#inputs-14" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(B x T x D)或(T x B x D),输入数据,B 是batch，T是time，D是input dim</li><li>weight_ih:T1,输入连接的weight</li><li>weight_hh:T1,hidden连接的weight</li><li>bias_ih:T2,输入连接的weight后的bias</li><li>bias_hh:T2,hidden连接的weight后的bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-15"></a>Outputs<a class="hash-link" href="#outputs-15" title="Direct link to heading">#</a></h3><ul><li>output:T3</li><li>hidden:T4</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-13"></a>Attr<a class="hash-link" href="#attr-13" title="Direct link to heading">#</a></h3><ul><li>scale_i:float,required,输入数据scale</li><li>scale_h:float,required,hidden scale</li><li>scale_iw:float,required,weight_ih的scale</li><li>scale_hw:float,required,weight_hh的scale</li><li>scale_io:float,optional,输入矩阵计算(Wi*Xi+Bi)的输出量化scale</li><li>scale_ho:float,optional,隐层矩阵计算(Wh*H+Bh)的输出量化scale</li><li>scale_o:float,optional,如果o_bits没有,scale_o为空</li><li>o_bits:int,optional,觉得输出是否做量化</li><li>platform_quant:string,required</li><li>data_bits:int,required</li><li>parameter_bits:int,required,weight_iw,weight_hw的数据位数</li><li>batch_first:int,required,1表明输入数据是否是B<em>T</em>D模式，0表明是T<em>B</em>D输入格式</li><li>dropout:float,required,对应标准lstm中的dropout操作，量化是全部为0，不做dropout操作</li><li>go_gorward:int,required,针对双向lstm的量化导出，1表示正向，0表示反向</li><li>num_layers:int,required,量化只支持num_layers=1</li><li>input_size:int,required,输入数据维度</li><li>hidden_size:int,required,隐层状态维度</li><li>table_len:int,optional,如果使用查表法,有此属性,表示表长度</li><li>sigmoid_bound:float,optional,sigmoid查表计算的查表边界</li><li>tanh_bound:float,optional,tanh查表计算的查表边界</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-15"></a>Type Constraints<a class="hash-link" href="#type-constraints-15" title="Direct link to heading">#</a></h3><ul><li><p>T1:tensor(int8)</p></li><li><p>T2:tensor(int32)</p></li><li><p>T3:tensor(int8)</p></li><li><p>T4:tensor(float32)</p></li><li><p>T5:tensor(int64)</p><p><img src="/docs-csk6/assets/images/gru_int-10e69eb1fc8cce7907d4440bbd0ecf89.png"></p></li></ul><hr><header><h1 class="h1Heading_5RMM">GRUInt_Is8_Is64</h1></header><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-15"></a>Inputs<a class="hash-link" href="#inputs-15" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(B x T x D)或(T x B x D),输入数据,B 是batch，T是time，D是input dim</li><li>batch_seq:T5,输入x的长度tensor，表示成list为[T0,T1,...],T0表示输入x的第0个tensor的T的实际长度,list长度为B</li><li>weight_ih:T1,输入连接的weight</li><li>weight_hh:T1,hidden连接的weight</li><li>bias_ih:T2,输入连接的weight后的bias</li><li>bias_hh:T2,hidden连接的weight后的bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-16"></a>Outputs<a class="hash-link" href="#outputs-16" title="Direct link to heading">#</a></h3><ul><li>output:T3</li><li>hidden:T4</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-14"></a>Attr<a class="hash-link" href="#attr-14" title="Direct link to heading">#</a></h3><ul><li>与GRUInt一致</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-16"></a>Type Constraints<a class="hash-link" href="#type-constraints-16" title="Direct link to heading">#</a></h3><ul><li><p>T1:tensor(int8)</p></li><li><p>T2:tensor(int32)</p></li><li><p>T3:tensor(int8)</p></li><li><p>T4:tensor(float32)</p></li><li><p>T5:tensor(int64)</p><p><img src="/docs-csk6/assets/images/gru_int_with_batch_length-3caf6d402b061b664f30480732b9a631.png"></p></li></ul><hr><header><h1 class="h1Heading_5RMM">GRUInt_Is8_Is64_If32</h1></header><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-16"></a>Inputs<a class="hash-link" href="#inputs-16" title="Direct link to heading">#</a></h3><ul><li>x:T1,格式(B x T x D)或(T x B x D),输入数据,B 是batch，T是time，D是input dim</li><li>batch_seq:T5,输入x的长度tensor，表示成list为[T0,T1,...],T0表示输入x的第0个tensor的T的实际长度,list长度为B</li><li>hidden_state:T4,隐层输入状态</li><li>weight_ih:T1,输入连接的weight</li><li>weight_hh:T1,hidden连接的weight</li><li>bias_ih:T2,输入连接的weight后的bias</li><li>bias_hh:T2,hidden连接的weight后的bias</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-17"></a>Outputs<a class="hash-link" href="#outputs-17" title="Direct link to heading">#</a></h3><ul><li>output:T3</li><li>hidden_state:T4</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-15"></a>Attr<a class="hash-link" href="#attr-15" title="Direct link to heading">#</a></h3><ul><li>与GRUInt一致</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-17"></a>Type Constraints<a class="hash-link" href="#type-constraints-17" title="Direct link to heading">#</a></h3><ul><li><p>T1:tensor(int8)</p></li><li><p>T2:tensor(int32)</p></li><li><p>T3:tensor(int8)</p></li><li><p>T4:tensor(float32)</p></li><li><p>T5:tensor(int64)</p><p><img src="/docs-csk6/assets/images/gru_int_with_batch_length_with_state-57663f8167a8feff957ec33c9b4331a9.png"></p></li></ul><hr><header><h1 class="h1Heading_5RMM">Quant</h1></header><ul><li>Quant主要是用来实现浮点输出转下一层定点输入的连接</li><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-17"></a>Inputs<a class="hash-link" href="#inputs-17" title="Direct link to heading">#</a></h3><ul><li>x:T1,要量化的float的tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-18"></a>Outputs<a class="hash-link" href="#outputs-18" title="Direct link to heading">#</a></h3><ul><li>y:T2,量化后的tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-16"></a>Attr<a class="hash-link" href="#attr-16" title="Direct link to heading">#</a></h3><ul><li>data_bits:int,required,量化bit数，当前支持小于等于8</li><li>scale_x:float,required,量化的scale</li><li>platform_quant:string,required,support luna_quant,其他方式策略一致</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-18"></a>Type Constraints<a class="hash-link" href="#type-constraints-18" title="Direct link to heading">#</a></h3><ul><li>T1:tensor(float)</li><li>T2:tensor(int8)</li></ul><hr><header><h1 class="h1Heading_5RMM">Dequant</h1></header><ul><li>Dequant主要是用来实现定点输出转下一层浮点输入的连接</li><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-18"></a>Inputs<a class="hash-link" href="#inputs-18" title="Direct link to heading">#</a></h3><ul><li>x:T1,输入定点tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-19"></a>Outputs<a class="hash-link" href="#outputs-19" title="Direct link to heading">#</a></h3><ul><li>y:T2,输出浮点tensor</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-17"></a>Attr<a class="hash-link" href="#attr-17" title="Direct link to heading">#</a></h3><ul><li>scale_o:float,required,浮点转定点的scale</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-19"></a>Type Constraints<a class="hash-link" href="#type-constraints-19" title="Direct link to heading">#</a></h3><ul><li>T1:tensor(int8)</li><li>T2:tensor(float)</li></ul><hr><header><h1 class="h1Heading_5RMM">BmmInt</h1></header><ul><li>用于torch.bmm的量化训练导出</li><li>linger导出</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="inputs-19"></a>Inputs<a class="hash-link" href="#inputs-19" title="Direct link to heading">#</a></h3><ul><li>x: T, 输入数据tensor, shape = (B<em>N</em>M)</li><li>y: T, 输入数据tensor, shape = (B<em>M</em>P)</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="outputs-20"></a>Outputs<a class="hash-link" href="#outputs-20" title="Direct link to heading">#</a></h3><ul><li>outputs:有o_bits属性为T，否则为T1</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="attr-18"></a>Attr<a class="hash-link" href="#attr-18" title="Direct link to heading">#</a></h3><ul><li>data_bits:int,required,输入数据量化bit位</li><li>o_bits:int,optional,输出数据量化bit位 </li><li>platform_quant:str, required 量化硬件平台参数</li><li>scale_x:float,required,输入x的量化scale</li><li>scale_y:float,required,输入y的量化scale</li><li>scale_o:float,optional,输出out的量化scale</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_k6ZT" id="type-constraints-20"></a>Type Constraints<a class="hash-link" href="#type-constraints-20" title="Direct link to heading">#</a></h3><ul><li>T:tensor(int8)</li><li>T1:tensor(float)</li></ul><p><img src="/docs-csk6/assets/images/bmm_int-a6396c67925a359fa34c0b79bf0a7a5d.png"></p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs-csk6/AIEcology/Thinker/Inference_Engine/thinker_packer"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">« 模型打包</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs-csk6/AIEcology/Thinker/Inference_Engine/Thinke_api"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Thinker API »</div></a></div></nav><div class="gitalk-wrapper"><ul class="gitalk-option"><li class="like"><i class="icon like-icon"></i> <span id="like_num">有帮助  0</span></li><li class="unlike"><i class="icon unlike-icon"></i> <span id="unlike_num">没帮助 0</span></li></ul></div></div></div><div class="col col--3" style="padding-left:0px"><div class="tableOfContents_k96L thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#算子目录" class="table-of-contents__link">算子目录</a></li><li><a href="#majorname-必需" class="table-of-contents__link">MajorName 必需</a></li><li><a href="#inputs-outputs-可选" class="table-of-contents__link">Inputs Outputs 可选</a></li><li><a href="#量化方式" class="table-of-contents__link">量化方式</a></li><li><a href="#scale说明" class="table-of-contents__link">Scale说明</a></li><li><a href="#mode参数值" class="table-of-contents__link">Mode参数值</a></li><li><a href="#onnx类型值" class="table-of-contents__link">onnx类型值</a><ul><li><a href="#类型说明" class="table-of-contents__link">类型说明</a></li><li><a href="#类型和值" class="table-of-contents__link">类型和值</a></li><li><a href="#inputs" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs" class="table-of-contents__link">Outputs</a></li><li><a href="#attr" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-1" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-1" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-1" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-1" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs1---" class="table-of-contents__link">Inputs（1 - ∞）</a></li><li><a href="#outputs-2" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-2" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-2" class="table-of-contents__link">Type Constraints</a></li><li><a href="#onnxinfer-implementation" class="table-of-contents__link">OnnxInfer Implementation</a></li><li><a href="#inputs-2" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-3" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-3" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-3" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-3" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-4" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-4" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-4" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-4" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-5" class="table-of-contents__link">Outputs</a></li><li><a href="#type-constraints-5" class="table-of-contents__link">Type Constraints</a></li><li><a href="#onnxinfer-implementation-1" class="table-of-contents__link">OnnxInfer Implementation</a></li><li><a href="#inputs-5" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-6" class="table-of-contents__link">Outputs</a></li><li><a href="#type-constraints-6" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-6" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-7" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-5" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-7" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-7" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-8" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-6" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-8" class="table-of-contents__link">Type Constraints</a></li><li><a href="#onnxinfer-implementation-2" class="table-of-contents__link">OnnxInfer Implementation</a></li><li><a href="#inputs-8" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-9" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-7" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-9" class="table-of-contents__link">Type Constraints</a></li><li><a href="#onnxinfer-implementation-3" class="table-of-contents__link">OnnxInfer Implementation</a></li><li><a href="#inputs-9" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-10" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-8" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-10" class="table-of-contents__link">Type Constraints</a></li><li><a href="#onnxinfer-implementation-4" class="table-of-contents__link">OnnxInfer Implementation</a></li><li><a href="#inputs-10" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-11" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-9" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-11" class="table-of-contents__link">Type Constraints</a></li><li><a href="#onnxinfer-implementation-5" class="table-of-contents__link">OnnxInfer Implementation</a></li><li><a href="#inputs-11" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-12" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-10" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-12" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-12" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-13" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-11" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-13" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-13" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-14" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-12" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-14" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-14" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-15" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-13" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-15" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-15" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-16" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-14" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-16" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-16" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-17" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-15" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-17" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-17" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-18" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-16" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-18" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-18" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-19" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-17" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-19" class="table-of-contents__link">Type Constraints</a></li><li><a href="#inputs-19" class="table-of-contents__link">Inputs</a></li><li><a href="#outputs-20" class="table-of-contents__link">Outputs</a></li><li><a href="#attr-18" class="table-of-contents__link">Attr</a></li><li><a href="#type-constraints-20" class="table-of-contents__link">Type Constraints</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 安徽聆思智能科技有限公司皖ICP备05001217号</div></div></div></footer></div>
<script src="/docs-csk6/assets/js/runtime~main.2d336c42.js"></script>
<script src="/docs-csk6/assets/js/main.70a533e0.js"></script>
<script>!function(e,n,s,t,d){e[s]=e[s]||function(){(e[s].a=e[s].a||[]).push(arguments)},(d=n.createElement("script")).async=!0,d.src="https://cdn.jsdelivr.net/simplemde/latest/simplemde.min.js",n.body.appendChild(d)}(window,document,"simplemde")</script></body>
</html>